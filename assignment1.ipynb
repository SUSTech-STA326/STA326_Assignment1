{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA326 Assignment 1: Data Collection\n",
    "This is an assignment that is openly available for the Data Science Practice (STA326). \n",
    "\n",
    "The assignment encapsulates a holistic approach towards data collection and analysis, covering a spectrum of data formats and sources. Our objective is to amass, process, and scrutinize data to unearth significant insights. The methodology is sectioned into four pivotal tasks: \n",
    "- Web scraping \n",
    "- JSON file analysis \n",
    "- Working with CSV files\n",
    "- Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests  # send request\n",
    "from bs4 import BeautifulSoup  # parse web pages\n",
    "import pandas as pd  # csv\n",
    "from time import sleep  # wait\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Web Scraping\n",
    "\n",
    "In this assignment, we will explore web scraping, which can often include diverse information from website, and also use the data for simple analysis. We take [douban](https://movie.douban.com/top250) as the target website in this assignment.\n",
    "\n",
    "### Scraping Rules\n",
    "\n",
    "1) If you are using another organization's website for scraping, make sure to check the website's terms & conditions. \n",
    "\n",
    "2) Do not request data from the website too aggressively (quickly) with your program (also known as spamming), as this may break the website. Make sure your program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
    "\n",
    "3) The layout of a website may change from time to time. Because of this, if you're scraping a website, make sure to revisit the site and rewrite your code as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Web Scrape\n",
    "\n",
    "In order to extract the data we want, we’ll start with extracting the whole web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a request header (to prevent anti-scraping)\n",
    "headers = {\n",
    "    'authority': 'curlconverter.com',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'if-modified-since': 'Fri, 15 Jul 2022 21:44:42 GMT',\n",
    "    'if-none-match': 'W/\"62d1dfca-3a58\"',\n",
    "    'referer': 'https://curlconverter.com/',\n",
    "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"102\", \"Microsoft Edge\";v=\"102\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Linux\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'cross-site',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36 Edg/102.0.1245.30',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process can be split into three steps:\n",
    "\n",
    "1. Make a variable called `url`, that stores the following URL (as a string):\n",
    "https://movie.douban.com/top250?start=0\n",
    "\n",
    "2. Now, to open the URL, use `requests.get()` and provide `url` and `headers` as its input. Store this in a variable called `page`.\n",
    "\n",
    "3. After that, make a variable called `soup` to parse the HTML using `BeautifulSoup`. Consider that there will be a method from `BeautifulSoup` that you'll need to call on to get the content from the page. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "url = \"https://movie.douban.com/top250?start=0\"\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert url\n",
    "assert page\n",
    "assert soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Data Extraction\n",
    "\n",
    "Extract the data (`name` and `star`) from the page and save it in the corresponding list like `movie_name` and `movie_star`. \n",
    "\n",
    "Make sure you extract it as a string.\n",
    "\n",
    "To do so, you have to use the soup object created in the above cell.\n",
    "\n",
    "**Hint**: from your soup variable, you can access this with `soup.select()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "movie_name = []  # movie name\n",
    "movie_star = []  # movie star\n",
    "\n",
    "# YOUR CODE HERE\n",
    "for i in tqdm(range(0,2)):\n",
    "    url = \"https://movie.douban.com/top250?start=\" + str(i*25)\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    for element in soup.find_all('div', {'class': 'hd'}):\n",
    "        title = ''\n",
    "        for sub_element in element.find_all('span', {'class': ['title', 'other']}):\n",
    "            title += sub_element.get_text().replace('\\xa0', ' ')\n",
    "        movie_name.append(title)\n",
    "\n",
    "    for element in soup.find_all('span', {'class': 'rating_num'}):\n",
    "        movie_star.append(element.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Collecting into a dataframe\n",
    "\n",
    "Create a dataframe `movie_df` and add the data from the lists above to it. \n",
    "- `movie_name` is the movie name. Set the column name as `movie name`\n",
    "- `movie_star` is the population estimate via star. Add it to the dataframe, and set the column name as `movie star`\n",
    "\n",
    "Make sure to check the head of your dataframe to see that everything looks right! ie: movie_df.head()\n",
    "\n",
    "Finally, you should save the DataFrame to a csv file under this folder`'./output'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name =  \"MovieDouban.csv\"\n",
    "csv_dir = \"./output\"\n",
    "\n",
    "# # YOUR CODE HERE\n",
    "movie_df = pd.DataFrame({'movie_name': movie_name, 'movie_star': movie_star})\n",
    "movie_df.to_csv(csv_dir + '/' + csv_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: JSON File Analysis\n",
    "\n",
    "After the initial phase of web scraping, we transition to analyzing pre-collected data, which is often stored in accessible and structured formats like JSON and CSV. This approach allows us to bypass the time-consuming process of data collection through web scraping for certain datasets that are already available, enabling us to dive directly into data analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In the section, you will first be working with a file called 'anon_user_dat.json'. You can find the given data under the folder `'./data/task2'`. This file contains information about some (fake) Tinder users. When creating an account, each Tinder user was asked to provide their first name, last name, work email (to verify the disclosed workplace), age, gender, phone # and zip code. Before releasing this data, a data scientist cleaned the data to protect the privacy of Tinder's users by removing the obvious personal identifiers: phone #, zip code, and IP address. However, the data scientist chose to keep each users' email addresses because when they visually skimmed a couple of the email addresses none of them seemed to have any of the users' actual names in them. This is where the data scientist made a huge mistake!\n",
    "\n",
    "Data Files:\n",
    "- anon_user_dat.json\n",
    "- employee_info.json\n",
    "\n",
    "\n",
    "We will take advantage of having the work email addresses by finding the employee information of different companies and matching that employee information with the information we have, in order to identify the names of the secret Tinder users!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Load data from JSON file \n",
    "\n",
    "Load the `anon_user_dat.json` json file into a pandas dataframe. Call it `df_personal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_personal = pd.read_json(f\"./data/task2/anon_user_dat.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(df_personal, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Check the first 10 emails \n",
    "\n",
    "Save the first 10 emails to a Series, and call it `sample_emails`. \n",
    "You should then print out this Series. ( Use print() )\n",
    "\n",
    "The purpose of this is to get a sense of how these work emails are structured and how we could possibly extract where each anonymous user seems to work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    gshoreson0@seattletimes.com\n",
      "1             eweaben1@salon.com\n",
      "2        akillerby2@gravatar.com\n",
      "3              gsainz3@zdnet.com\n",
      "4       bdanilewicz4@4shared.com\n",
      "5      sdeerness5@wikispaces.com\n",
      "6         jstillwell6@ustream.tv\n",
      "7         mpriestland7@opera.com\n",
      "8       nerickssen8@hatena.ne.jp\n",
      "9             hparsell9@xing.com\n",
      "Name: email, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "sample_emails = df_personal['email'][0:10]\n",
    "print(sample_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(sample_emails, pd.Series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Extract the Company Name From the Email \n",
    "\n",
    "Create a function with the following specifications:\n",
    "- Function Name: extract_company\n",
    "- Purpose: to extract the company of the email (i.e., everything after the @ sign but before the first .)\n",
    "- Parameter(s): email (string)\n",
    "- Returns: The extracted part of the email (string)\n",
    "- Hint: This should take 1 line of code. Look into the find('') method. \n",
    "\n",
    "You can start with this outline:\n",
    "```python \n",
    "def extract_company(email):\n",
    "    return\n",
    "```\n",
    "\n",
    "Example Usage: \n",
    "- extract_company(\"larhe@uber.com\") should return \"uber\"\n",
    "- extract_company(“ds@cogs.edu”) should return “cogs”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def extract_company(email):\n",
    "    email = email.split('@')[1]\n",
    "    email = email.split('.')[0]\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert extract_company(\"gshoreson0@seattletimes.com\") == \"seattletimes\"\n",
    "assert extract_company(\"amcgeffen1d@goo.ne.jp\") == 'goo'\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a little bit of basic sleuthing (aka googling) and web-scraping (aka selectively reading in html code) it turns out that you've been able to collect information about all the present employees/interns of the companies you are interested in. Specifically, on each company website, you have found the name, gender, and age of its employees. You have saved that info in employee_info.json and plan to see if, using this new information, you can match the Tinder accounts to actual names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d) Load in employee data \n",
    "\n",
    "Load the json file into a pandas dataframe. Call it `df_employee`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_employee = pd.read_json(f\"./data/task2/employee_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(df_employee, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e) Match the employee name with company, age, gender \n",
    "\n",
    "Create a function with the following specifications:\n",
    "- Function name: employee_matcher\n",
    "- Purpose: to match the employee name with the provided company, age, and gender\n",
    "- Parameter(s): company (string), age (int), gender (string)\n",
    "- Returns: The employee first_name and last_name like this: return first_name, last_name \n",
    "- Note: If there are multiple employees that fit the same description, first_name and last_name should return a list of all possible first names and last names i.e., ['Desmund', 'Kelby'], ['Shepley', 'Tichner']. Note that the names of the individuals that would produce this output are 'Desmund Shepley' and 'Kelby Tichner'.\n",
    "\n",
    "Hint:\n",
    "There are many different ways to code this. An inelegant solution is to loop through `df_employee` \n",
    "   and for each data item see if the company, age, and gender match\n",
    "   i.e., \n",
    "   ```python\n",
    "   for i in range(0, len(df_employee)):\n",
    "             if (company == df_employee.loc[i,'company']):\n",
    "   ```\n",
    "   \n",
    "However! The solution above is very inefficient and long, so you should try to look into this:\n",
    "Google the df.loc method: It extracts pieces of the dataframe\n",
    "   if it fulfills a certain condition.\n",
    "   i.e., \n",
    "   \n",
    "```python\n",
    "df_employee.loc[df_employee['company'] == company]\n",
    "```\n",
    "\n",
    "If you need to convert your pandas data series into a list, you can do ```list(result)``` where result is a pandas \"series\"\n",
    "\n",
    "You can start with this outline:\n",
    "```python\n",
    "def employee_matcher(company, age, gender):\n",
    "    return first_name, last_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def employee_matcher(company, age, gender):\n",
    "    matched = df_employee.loc[(df_employee['company'] == company) & (df_employee['age'] == age) & (df_employee['gender'] == gender)]\n",
    "    first_name = list(matched['first_name'])\n",
    "    last_name = list(matched['last_name'])\n",
    "    return first_name, last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert employee_matcher(\"google\", 41, \"Male\") == (['Maxwell'], ['Jorio'])\n",
    "assert employee_matcher(\"salon\", 47, \"Female\") == (['Elenore'], ['Gravett'])\n",
    "assert employee_matcher(\"webmd\", 28, \"Nonbinary\") == (['Zaccaria'], ['Bartosiak'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2f) Extract all the private data \n",
    "\n",
    "- Create 2 empty lists called `first_names` and `last_names`\n",
    "- Loop through all the people we are trying to identify in df_personal\n",
    "- Call the `extract_company` function (i.e., `extract_company(df_personal.loc[i, 'email'])` )\n",
    "- Call the `employee_matcher` function \n",
    "- Append the results of `employee_matcher` to the appropriate lists (`first_names` and `last_names`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "first_names = []\n",
    "last_names = []\n",
    "\n",
    "for i in range(len(df_personal)):\n",
    "    company = extract_company(df_personal.loc[i, 'email'])\n",
    "    age = df_personal.loc[i, 'age']\n",
    "    gender = df_personal.loc[i, 'gender']\n",
    "    first_name, last_name = employee_matcher(company, age, gender)\n",
    "    first_names.append(first_name)\n",
    "    last_names.append(last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert first_names[45:50]== [['Justino'], ['Tadio'], ['Kennith'], ['Cedric'], ['Amargo']]\n",
    "assert last_names[45:50] == [['Corro'], ['Blackford'], ['Milton'], ['Yggo'], ['Grigor']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2g) Add the names to the original 'secure' dataset! \n",
    "\n",
    "We have done this last step for you below, all you need to do is run this cell.\n",
    "\n",
    "For your own personal enjoyment, you should also print out the new `df_personal` with the identified people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personal['first_name'] = first_names\n",
    "df_personal['last_name'] = last_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>gshoreson0@seattletimes.com</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Gordon]</td>\n",
       "      <td>[DelaField]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>eweaben1@salon.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Elenore]</td>\n",
       "      <td>[Gravett]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>akillerby2@gravatar.com</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Abbe]</td>\n",
       "      <td>[Stockdale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>gsainz3@zdnet.com</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Guido]</td>\n",
       "      <td>[Comfort]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>bdanilewicz4@4shared.com</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Brody]</td>\n",
       "      <td>[Pinckard]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3</td>\n",
       "      <td>pstroulgerrn@time.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Penelopa]</td>\n",
       "      <td>[Roman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>49</td>\n",
       "      <td>kbasnettro@seattletimes.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Anthiathia, Kandy]</td>\n",
       "      <td>[Baldwin, Cossam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>75</td>\n",
       "      <td>pmortlockrp@liveinternet.ru</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Paco]</td>\n",
       "      <td>[Weatherburn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>81</td>\n",
       "      <td>sphetterq@toplist.cz</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Sammy]</td>\n",
       "      <td>[Dymick]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>70</td>\n",
       "      <td>jtyresrr@slashdot.org</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Josiah]</td>\n",
       "      <td>[Ayshford]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age                        email  gender           first_name  \\\n",
       "0     60  gshoreson0@seattletimes.com    Male             [Gordon]   \n",
       "1     47           eweaben1@salon.com  Female            [Elenore]   \n",
       "2     27      akillerby2@gravatar.com    Male               [Abbe]   \n",
       "3     46            gsainz3@zdnet.com    Male              [Guido]   \n",
       "4     72     bdanilewicz4@4shared.com    Male              [Brody]   \n",
       "..   ...                          ...     ...                  ...   \n",
       "995    3        pstroulgerrn@time.com  Female           [Penelopa]   \n",
       "996   49  kbasnettro@seattletimes.com  Female  [Anthiathia, Kandy]   \n",
       "997   75  pmortlockrp@liveinternet.ru    Male               [Paco]   \n",
       "998   81         sphetterq@toplist.cz    Male              [Sammy]   \n",
       "999   70        jtyresrr@slashdot.org    Male             [Josiah]   \n",
       "\n",
       "             last_name  \n",
       "0          [DelaField]  \n",
       "1            [Gravett]  \n",
       "2          [Stockdale]  \n",
       "3            [Comfort]  \n",
       "4           [Pinckard]  \n",
       "..                 ...  \n",
       "995            [Roman]  \n",
       "996  [Baldwin, Cossam]  \n",
       "997      [Weatherburn]  \n",
       "998           [Dymick]  \n",
       "999         [Ayshford]  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_personal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Working with CSV Files\n",
    "Continuing with our exploration of pre-collected data formats, we delve into CSV files, which are renowned for their simplicity and widespread use in representing tabular data. This stage involves leveraging libraries like pandas in Python, which simplify the process of reading, manipulating, and analyzing CSV data. \n",
    "\n",
    "### Overview\n",
    "\n",
    "For this assignment, you are provided with two data files that contain information on a sample of people. The two files and their columns are:\n",
    "\n",
    "- `age_steps.csv`: Contains one row for each person.\n",
    "    - `id`: Unique identifier for the person.\n",
    "    - `age`: Age of the person.\n",
    "    - `steps`: Number of steps the person took on average in January 2018.\n",
    "    \n",
    "    \n",
    "- `incomes.json`: Contains one record for each person.\n",
    "    - `id`: Unique identifier for the person. Two records with the same ID between `age_steps.csv` and `incomes.json` correspond to the same person.\n",
    "    - `last_name`: Last name of the person.\n",
    "    - `first_name`: First name of the person.\n",
    "    - `income`: Income of the person in 2018.\n",
    "    \n",
    "You can find the given data under the folder `'./data/task3'`. To finish the assignment, we recommend looking at the official 10 minutes to pandas guide: http://pandas.pydata.org/pandas-docs/stable/10min.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3a:** Load the `age_steps.csv` file into a `pandas` DataFrame named `df_steps`. It should have 11257 rows and 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_steps = pd.read_csv(\"./data/task3/age_steps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(df_steps, pd.DataFrame)\n",
    "assert df_steps.shape == (11257, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3b:** Load the `incomes.json` file into a `pandas` DataFrame called `df_income`. The DataFrame should have 13332 rows and 4 columns. \n",
    "\n",
    "Hint: Find a pandas function similar to `read_csv` for JSON files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_income = pd.read_json(\"./data/task3/incomes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(df_income, pd.DataFrame)\n",
    "assert df_income.shape == (13332, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3c:** Drop the `first_name` and `last_name` columns from the `df_income` DataFrame. The resulting DataFrame should only have two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_income = df_income.drop(columns=['first_name', 'last_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'first_name' not in df_income.columns\n",
    "assert 'last_name' not in df_income.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3d:** Merge the `df_steps` and `df_income` DataFrames into a single combined DataFrame called `df`. Use the `id` column to match rows together.\n",
    "\n",
    "The final DataFrame should have 10,135 rows and 4 columns: `id`, `income`, `age`, and `steps`.\n",
    "\n",
    "Call an appropriate `pandas` method to perform this operation; don't write a `for` loop. (In general, writing a `for` loop for a DataFrame will produce poor results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df = pd.merge(df_steps, df_income, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(df, pd.DataFrame)\n",
    "assert set(df.columns) == set(['id', 'income', 'age', 'steps'])\n",
    "assert df.shape == (10135, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3e:** Reorder the columns of `df` so that they appear in the order: `id`, `age`, `steps`, then `income`.\n",
    "\n",
    "(Note: If your DataFrame is already in this order, just put `df` in this cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>steps</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36859</td>\n",
       "      <td>48</td>\n",
       "      <td>6764</td>\n",
       "      <td>10056.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99794</td>\n",
       "      <td>39</td>\n",
       "      <td>4308</td>\n",
       "      <td>13869.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33364</td>\n",
       "      <td>36</td>\n",
       "      <td>6410</td>\n",
       "      <td>79634.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73874</td>\n",
       "      <td>35</td>\n",
       "      <td>7870</td>\n",
       "      <td>12369.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66956</td>\n",
       "      <td>56</td>\n",
       "      <td>7670</td>\n",
       "      <td>41150.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10130</th>\n",
       "      <td>42474</td>\n",
       "      <td>28</td>\n",
       "      <td>7307</td>\n",
       "      <td>49128.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131</th>\n",
       "      <td>61626</td>\n",
       "      <td>44</td>\n",
       "      <td>7752</td>\n",
       "      <td>20096.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10132</th>\n",
       "      <td>52336</td>\n",
       "      <td>41</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10133</th>\n",
       "      <td>54972</td>\n",
       "      <td>44</td>\n",
       "      <td>7548</td>\n",
       "      <td>18350.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10134</th>\n",
       "      <td>17411</td>\n",
       "      <td>43</td>\n",
       "      <td>8765</td>\n",
       "      <td>88965.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10135 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  age  steps    income\n",
       "0      36859   48   6764  10056.43\n",
       "1      99794   39   4308  13869.47\n",
       "2      33364   36   6410  79634.92\n",
       "3      73874   35   7870  12369.03\n",
       "4      66956   56   7670  41150.18\n",
       "...      ...  ...    ...       ...\n",
       "10130  42474   28   7307  49128.60\n",
       "10131  61626   44   7752  20096.38\n",
       "10132  52336   41     -1      0.00\n",
       "10133  54972   44   7548  18350.20\n",
       "10134  17411   43   8765  88965.55\n",
       "\n",
       "[10135 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(df.columns) == ['id', 'age', 'steps', 'income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3f:** You may have noticed something strange: the merged `df` DataFrame has fewer rows than either of `df_steps` and `df_income`. Why did this happen? (If you're unsure, check out the documentation for the `pandas` method you used to merge these two datasets. Take note of the default values set for this method's parameters.)\n",
    "\n",
    "Please select the **one** correct explanation below and save your answer in the variable `q1f_answer`. For example, if you believe choice number 4 explains why `df` has fewer rows, set `q1f_answer = 4`.\n",
    "\n",
    "1. Some steps were recorded inaccurately in `df_steps`.\n",
    "2. Some incomes were recorded inaccurately in `df_income`.\n",
    "3. There are fewer rows in `df_steps` than in `df_income`.\n",
    "4. There are fewer columns in `df_steps` than in `df_income`.\n",
    "5. Some `id` values in either `df_steps` and `df_income` were missing in the other DataFrame.\n",
    "6. Some `id` values were repeated in `df_steps` and in `df_income`.\n",
    "\n",
    "You may use the cell below to run whatever code you want to check the statements above. Just make sure to set `q1f_answer` once you've selected a choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "q1f_answer = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(q1f_answer, int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Data Cleaning\n",
    "\n",
    "Post data collection, a pivotal step ensues—Data Cleaning. This phase is crucial for ensuring the reliability and accuracy of our analysis. It involves scrutinizing the data for inaccuracies, inconsistencies, and incompleteness. Techniques such as removing duplicates, handling missing values, and correcting errors are employed to refine the dataset. A common phenomenon is that the collected data may contain missing values. Here are two common ones:\n",
    "\n",
    "- **Nonresponse.** For example, people might have left a field blank when responding to a survey, or left the entire survey blank.\n",
    "- **Lost in entry.** Data might have been lost after initial recording. For example, a disk cleanup might accidentally wipe older entries of a database.\n",
    "\n",
    "In general, it is **not** appropriate to simply drop missing values from the dataset or pretend that if filled in they would not change your results. In 2016, many polls mistakenly predicted that Hillary Clinton would easily win the Presidential election by committing this error. In this particular dataset, however, the **missing values occur completely at random**. This criteria allows us to drop missing values without significantly affecting our conclusions.\n",
    "\n",
    "In this section, we continue use the data mentioned in Part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4a:** How many values are missing in the `income` column of `df`? Save this number into a variable called `n_nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# count the nan values of income\n",
    "n_nan = df['income'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(n_nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4b:** Remove all rows from `df` that have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows from df that have missing data. In other words, remove all rows with NaN values.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(np.isnan(df['income'])) == 0\n",
    "assert df.shape == (9684, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4c:** Note that we can now compute the average income. If your `df` variable contains the right values, `df['income'].mean()` should produce the value `25508.84`.\n",
    "\n",
    "Suppose that we didn't drop the missing incomes. What will running `df['income'].mean()` output? Use the variable `q2c_answer` to record which of the below statements you think is true. As usual, you can use the cell below to run any code you'd like in order to help you answer this question as long as you set `q2c_answer` once you've finished.\n",
    "\n",
    "1. No change; `df['income'].mean()` will ignore the missing values and output `25508.84`.\n",
    "2. `df['income'].mean()` will produce an error.\n",
    "3. `df['income'].mean()` will output `0`.\n",
    "4. `df['income'].mean()` will output `nan` (not a number).\n",
    "5. `df['income'].mean()` will fill in the missing values with the average income, then compute the average.\n",
    "6. `df['income'].mean()` will fill in the missing values with `0`, then compute the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output mean if not drop nan: 25508.83871127633\n",
      "After compute the mean, the # of nan in income is: 451\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df_t = pd.merge(df_steps, df_income, on='id', how='inner')\n",
    "print(\"The output mean if not drop nan:\", df_t['income'].mean())\n",
    "print(\"After compute the mean, the # of nan in income is:\", df_t['income'].isna().sum())\n",
    "q2c_answer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(q2c_answer, int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4d:** Suppose that missing incomes did not occur at random, and that individuals with incomes below \\$10000 a year are less likely to report their incomes. If so, which of the following statements below is true? Record your choice in the variable `q2d_answer`.\n",
    "\n",
    "1. `df['income'].mean()` will likely output a value that is the same as the population's average income\n",
    "2. `df['income'].mean()` will likely output a value that is smaller than the population's average income.\n",
    "3. `df['income'].mean()` will likely output a value that is larger than the population's average income.\n",
    "4. `df['income'].mean()` will raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "q2d_answer = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(q2d_answer, int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete!\n",
    "\n",
    "Congrats, you're done!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
